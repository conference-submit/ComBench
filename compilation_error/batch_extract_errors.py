#!/usr/bin/env python3
"""
Batch extraction of compilation errors script

Automatically detect which repositories have input files but no output files, then call extract_compiler_errors.py in parallel for processing
"""

import os
import subprocess
import sys
from pathlib import Path

def get_existing_output_files():
    """Get existing output files in compilation_error folder"""
    compilation_error_dir = Path(__file__).parent
    existing_files = set()
    
    for file_path in compilation_error_dir.glob("*_compiler_errors_extracted.json"):
        # Extract repository name
        filename = file_path.name
        repo_name = filename.replace("_compiler_errors_extracted.json", "")
        existing_files.add(repo_name)
    
    return existing_files

def get_available_input_files():
    """Get available input files in ci_failures folder"""
    ci_failures_dir = Path(__file__).parent.parent / "ci_failures"
    available_repos = set()
    
    for file_path in ci_failures_dir.glob("*_ci_failures.json"):
        # Extract repository name
        filename = file_path.name
        repo_name = filename.replace("_ci_failures.json", "")
        available_repos.add(repo_name)
    
    return available_repos

def count_lines_with_wc(file_path):
    """Use wc -l to count file lines"""
    try:
        result = subprocess.run(['wc', '-l', str(file_path)], capture_output=True, text=True)
        if result.returncode == 0:
            return int(result.stdout.strip().split()[0])
        else:
            print(f"wc -l count for {file_path} failed: {result.stderr}")
            return 0
    except Exception as e:
        print(f"Error counting lines in {file_path}: {e}")
        return 0

def print_unprocessed_file_stats(repos_to_process):
    """æ‰“å°æœªå¤„ç†æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨wc -lï¼‰"""
    ci_failures_dir = Path(__file__).parent.parent / "ci_failures"
    print(f"\n{'='*60}")
    print("æœªå¤„ç†æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯ (æŒ‰ç‰©ç†è¡Œæ•°)")
    print(f"{'='*60}")
    total_lines = 0
    file_stats = []
    for repo in sorted(repos_to_process):
        input_file = ci_failures_dir / f"{repo}_ci_failures.json"
        if input_file.exists():
            line_count = count_lines_with_wc(input_file)
            total_lines += line_count
            file_stats.append((repo, line_count))
            print(f"  {repo}: {line_count:,} è¡Œ")
    print(f"\næ€»è®¡: {len(file_stats)} ä¸ªæ–‡ä»¶ï¼Œ{total_lines:,} è¡Œæ•°æ®")
    print(f"{'='*60}")


def start_background_process(repo_name):
    """å¯åŠ¨åå°è¿›ç¨‹å¤„ç†æŒ‡å®šä»“åº“"""
    try:
        cmd = [sys.executable, "extract_compiler_errors.py", repo_name]
        print(f"ğŸš€ å¯åŠ¨åå°è¿›ç¨‹: {repo_name.upper()}")
        
        # åœ¨åå°è¿è¡Œï¼Œä¸ç­‰å¾…å®Œæˆ
        process = subprocess.Popen(
            cmd, 
            cwd=Path(__file__).parent,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        
        print(f"âœ… {repo_name.upper()} åå°è¿›ç¨‹å·²å¯åŠ¨ (PID: {process.pid})")
        return True
        
    except Exception as e:
        print(f"âŒ {repo_name.upper()} å¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("æ‰¹é‡ç¼–è¯‘é”™è¯¯æå–å·¥å…· (åå°å¹¶è¡Œç‰ˆæœ¬)")
    print("="*60)
    
    # è·å–å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
    existing_outputs = get_existing_output_files()
    print(f"å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶: {sorted(existing_outputs)}")
    
    # è·å–å¯ç”¨çš„è¾“å…¥æ–‡ä»¶
    available_inputs = get_available_input_files()
    print(f"å¯ç”¨çš„è¾“å…¥æ–‡ä»¶: {sorted(available_inputs)}")
    
    # æ‰¾å‡ºéœ€è¦å¤„ç†çš„ä»“åº“
    repos_to_process = available_inputs - existing_outputs
    print(f"\néœ€è¦å¤„ç†çš„ä»“åº“: {sorted(repos_to_process)}")
    
    if not repos_to_process:
        print("æ‰€æœ‰ä»“åº“éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    # æ˜¾ç¤ºå°†è¦å¤„ç†çš„ä»“åº“
    print(f"\nå°†å¤„ç† {len(repos_to_process)} ä¸ªä»“åº“:")
    for repo in sorted(repos_to_process):
        print(f"  - {repo}")
    
    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    response = input(f"\nå°†å¯åŠ¨ {len(repos_to_process)} ä¸ªåå°è¿›ç¨‹ã€‚æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
    if response.lower() != 'y':
        print("æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ‰“å°æœªå¤„ç†æ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
    print_unprocessed_file_stats(repos_to_process)

    # å¯åŠ¨æ‰€æœ‰åå°è¿›ç¨‹
    print("\nå¼€å§‹å¯åŠ¨åå°è¿›ç¨‹...")
    success_count = 0
    
    for repo in sorted(repos_to_process):
        if start_background_process(repo):
            success_count += 1
    
    # è¾“å‡ºç»“æœ
    print(f"\n{'='*60}")
    print("åå°è¿›ç¨‹å¯åŠ¨å®Œæˆ")
    print(f"{'='*60}")
    print(f"æˆåŠŸå¯åŠ¨: {success_count}/{len(repos_to_process)} ä¸ªåå°è¿›ç¨‹")
    print("æ‰€æœ‰è¿›ç¨‹å°†åœ¨åå°è¿è¡Œï¼Œè¯·ç¨åæ£€æŸ¥è¾“å‡ºæ–‡ä»¶")
    print("å¯ä»¥ä½¿ç”¨ 'ps aux | grep extract_compiler_errors' æŸ¥çœ‹è¿è¡Œä¸­çš„è¿›ç¨‹")

if __name__ == "__main__":
    main() 