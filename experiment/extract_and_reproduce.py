#!/usr/bin/env python3
"""
Extract parameters from JSON files in compilation_error directory and automatically reproduce compilation errors

This script reads error records from the specified project's *_compiler_errors_extracted.json file,
and automatically runs reproduction scripts to reproduce compilation errors.

Usage:
    python extract_and_reproduce.py --project <project_name> [options]

Parameters:
    --project STR         Project name to process (required, e.g.: llvm, opencv)

Options:
    --line-number N       Process record with specified line number (starting from 1)
    --first-n N           Process first N records
    --dry-run             Only show operations to be performed, do not actually run
    --rebuild             Force rebuild environment
    --no-switch           Do not switch to specified commit
    --list                List all available records
    --repo-path PATH      æŒ‡å®šä»“åº“è·¯å¾„ (é»˜è®¤ä½¿ç”¨é¡¹ç›®é…ç½®ä¸­çš„è·¯å¾„)
    --reuse-log PATH      æŒ‡å®šè¦å¤ç”¨çš„æ—¥å¿—ç›®å½•æˆ–æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä¸é‡æ–°è¿è¡Œå¤ç°è„šæœ¬
    
ç¤ºä¾‹:
    python extract_and_reproduce.py --project llvm --line-number 1
    python extract_and_reproduce.py --project opencv --first-n 3 --rebuild
    python extract_and_reproduce.py --project curl --no-switch
    python extract_and_reproduce.py --project curl --list
    python extract_and_reproduce.py --project llvm --repo-path /path/to/llvm
    python extract_and_reproduce.py --project llvm --line-number 1 --reuse-log
"""

import argparse
import json
import subprocess
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from path_config import get_path, get_compilation_error_file, get_repair_patch_file, get_project_repo_path

# è®¾ç½®æ ‡å‡†è¾“å‡ºæ— ç¼“å†²
import sys
import io
sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)


def load_project_config(project_name):
    """åŠ è½½é¡¹ç›®é…ç½®"""
    config_file = get_path('project_configs')
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            configs = json.load(f)
        
        if project_name not in configs:
            print(f"è­¦å‘Š: é¡¹ç›® '{project_name}' åœ¨é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°")
            return None
        
        return configs[project_name]
        
    except FileNotFoundError:
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None


def select_compilable_job(job_names, project_config):
    """æ ¹æ®é¡¹ç›®é…ç½®é€‰æ‹©å¯ç¼–è¯‘çš„job"""
    if not project_config:
        # å¦‚æœæ²¡æœ‰é¡¹ç›®é…ç½®ï¼Œè¿”å›ç¬¬ä¸€ä¸ªjob
        if isinstance(job_names, list) and job_names:
            return job_names[0]
        return job_names
    
    reproducible_jobs = project_config.get('reproducible_jobs', [])
    
    if not reproducible_jobs:
        print("è­¦å‘Š: é¡¹ç›®é…ç½®ä¸­æ²¡æœ‰å¯å¤ç°çš„jobåˆ—è¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªjob")
        if isinstance(job_names, list) and job_names:
            return job_names[0]
        return job_names
    
    # å¦‚æœjob_namesæ˜¯å•ä¸ªå­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(job_names, str):
        job_names = [job_names]
    
    # ä¼˜å…ˆé€‰æ‹©åœ¨reproducible_jobsä¸­çš„job
    for job in job_names:
        if job in reproducible_jobs:
            print(f"é€‰æ‹©å¯ç¼–è¯‘çš„job: {job}")
            return job
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯ç¼–è¯‘çš„jobï¼Œè¿”å›None
    print("é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å¯ç¼–è¯‘çš„jobï¼Œè·³è¿‡æ­¤è®°å½•")
    return None


def load_compiler_errors_data(jsonl_file, project_name):
    """ä»find_repair_patchç›®å½•çš„JSONLæ–‡ä»¶ä¸­åŠ è½½ç¼–è¯‘é”™è¯¯æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»compilation_errorç›®å½•è¯»å–JSONæ•°æ®"""
    records = []
    
    # é¦–å…ˆå°è¯•ä»JSONLæ–‡ä»¶è¯»å–
    try:
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                if line.strip():
                    record = json.loads(line.strip())
                    # æ·»åŠ è¡Œå·ä¿¡æ¯
                    record['_line_number'] = line_num
                    # JSONLæ–‡ä»¶ä¸­å·²ç»æœ‰failure_commitå­—æ®µï¼Œä¸éœ€è¦æ˜ å°„
                    records.append(record)
        print(f"ä»JSONLæ–‡ä»¶åŠ è½½äº† {len(records)} æ¡è®°å½•")
        return records
            
    except FileNotFoundError:
        print(f"JSONLæ–‡ä»¶ä¸å­˜åœ¨: {jsonl_file}")
        print("å°è¯•ä»compilation_errorç›®å½•è¯»å–JSONæ•°æ®...")
        
        # ä»compilation_errorç›®å½•è¯»å–JSONæ•°æ®
        json_file = get_compilation_error_file(project_name)
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ä»JSONæ•°æ®ä¸­æå–compiler_errorsæ•°ç»„
            if 'compiler_errors' in data:
                compiler_errors = data['compiler_errors']
                for line_num, record in enumerate(compiler_errors, 1):
                    # æ·»åŠ è¡Œå·ä¿¡æ¯
                    record['_line_number'] = line_num
                    # å°†commit_shaæ˜ å°„ä¸ºfailure_commitä»¥ä¿æŒå…¼å®¹æ€§
                    if 'commit_sha' in record:
                        record['failure_commit'] = record['commit_sha']
                    records.append(record)
                
                print(f"ä»JSONæ–‡ä»¶åŠ è½½äº† {len(records)} æ¡è®°å½•")
                return records
            else:
                print(f"é”™è¯¯: JSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°compiler_errorså­—æ®µ")
                sys.exit(1)
                
        except FileNotFoundError:
            print(f"é”™è¯¯: JSONæ–‡ä»¶ä¹Ÿä¸å­˜åœ¨: {json_file}")
            sys.exit(1)
        except Exception as e:
            print(f"é”™è¯¯: è¯»å–JSONæ–‡ä»¶å¤±è´¥: {e}")
            sys.exit(1)
            
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–JSONLæ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)


def list_records(records, project_name, project_config=None):
    """åˆ—å‡ºæ‰€æœ‰è®°å½•"""
    print(f"é¡¹ç›® '{project_name}' çš„å¯ç”¨è®°å½•:")
    print("=" * 80)
    
    for record in records:
        line_num = record.get('_line_number', '?')
        failure_commit = record.get('failure_commit', 'N/A')[:12]
        workflow_name = record.get('workflow_name', 'N/A')
        job_name = record.get('job_name', 'N/A')
        
        # æ ¹æ®é¡¹ç›®é…ç½®é€‰æ‹©å¯ç¼–è¯‘çš„job
        compilable_job_name = select_compilable_job(job_name, project_config)
        
        error_count = len(record.get('error_lines', []))
        
        print(f"è¡Œå·: {line_num}")
        print(f"  å¤±è´¥commit: {failure_commit}")
        print(f"  Workflow: {workflow_name}")
        print(f"  ä½œä¸š: {compilable_job_name}")
        print(f"  é”™è¯¯æ•°é‡: {error_count}")
        print("-" * 40)


def run_reproduction(project_name, failure_commit, job_name, workflow_name, line_number=None, dry_run=False, rebuild=False, no_switch=False, repo_path=None, reuse_log=None):
    """è¿è¡Œå¤ç°è„šæœ¬"""
    # æ„é€ æ—¥å¿—æ–‡ä»¶åï¼ˆå’Œreproduce_compiler_errors.pyä¸€è‡´ï¼‰
    line_num = line_number if line_number is not None else 0
    log_file = f"logs/act_{project_name}_line{line_num}.log"
    script_dir = Path(__file__).parent
    log_file_path = script_dir / log_file
    
    # å¦‚æœæ˜¾å¼æŒ‡å®šäº†å¤ç”¨æ—¥å¿—è·¯å¾„ï¼Œåˆ™ä¼˜å…ˆå°†å…¶ä½œä¸ºç›®å½•å¤„ç†ï¼Œæ‰¾é»˜è®¤æ—¥å¿—æ–‡ä»¶ï¼›è‹¥æ˜¯æ–‡ä»¶å°±ç›´æ¥è¯»å–
    if reuse_log:
        reuse_path = Path(reuse_log)
        candidate_file = None
        if reuse_path.is_dir():
            candidate_file = reuse_path / f"act_{project_name}_line{line_num}.log"
        elif reuse_path.is_file():
            candidate_file = reuse_path
        else:
            # æ—¢ä¸æ˜¯å­˜åœ¨çš„ç›®å½•ä¹Ÿä¸æ˜¯æ–‡ä»¶ï¼Œç›´æ¥å¤±è´¥
            print(f"âŒ æŒ‡å®šçš„å¤ç”¨æ—¥å¿—è·¯å¾„ä¸å­˜åœ¨: {reuse_path}")
            return False

        if candidate_file.exists():
            print(f"âœ… å¯ç”¨å¤ç”¨æ¨¡å¼ï¼Œä½¿ç”¨æ—¥å¿—: {candidate_file}")
            try:
                with open(candidate_file, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                print(f"\nğŸ“„ æ—¥å¿—æ–‡ä»¶å†…å®¹:")
                print("=" * 80)
                print(log_content)
                print("=" * 80)
            except Exception as e:
                print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
                return False
            print("âœ… ç¼–è¯‘é”™è¯¯å¤ç°éªŒè¯æˆåŠŸ (å¤ç”¨æ¨¡å¼)")
            return True
        else:
            print(f"âŒ æœªæ‰¾åˆ°å¯å¤ç”¨çš„æ—¥å¿—æ–‡ä»¶: {candidate_file}")
            return False
    
    # ä½¿ç”¨ç»å¯¹è·¯å¾„è°ƒç”¨reproduce_error.py
    reproduce_script = script_dir / 'reproduce_error.py'
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»“åº“è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if not repo_path:
        try:
            repo_path = get_project_repo_path(project_name)
        except KeyError:
            print(f"è­¦å‘Š: é¡¹ç›® '{project_name}' çš„ä»“åº“è·¯å¾„æœªé…ç½®ï¼Œè¯·ä½¿ç”¨ --repo-path å‚æ•°æŒ‡å®š")
            return False
    
    # ä½¿ç”¨æ–°çš„ç¼–è¯‘é”™è¯¯å¤ç°è„šæœ¬
    cmd = [
        'python3', str(reproduce_script),
        project_name, failure_commit, job_name, workflow_name
    ]
    
    if line_number:
        cmd.extend(['--line-number', str(line_number)])
    
    if dry_run:
        cmd.append('--dry-run')  # æ³¨æ„ï¼šæ–°è„šæœ¬å¯èƒ½ä¸æ”¯æŒdry_runï¼Œä½†å…ˆä¿ç•™
    
    if rebuild:
        cmd.append('--force-rebuild')
    
    if no_switch:
        cmd.append('--no-switch')
    
    if repo_path:
        cmd.extend(['--repo-path', repo_path])
    
    print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=False)
        success = result.returncode == 0
        
        if success:
            print("âœ… ç¼–è¯‘é”™è¯¯å¤ç°éªŒè¯æˆåŠŸ")
        else:
            print("âŒ ç¼–è¯‘é”™è¯¯å¤ç°éªŒè¯å¤±è´¥")
        
        return success
    except Exception as e:
        print(f"é”™è¯¯: è¿è¡Œå¤ç°è„šæœ¬å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Extract parameters from JSON files in compilation_error directory and automatically reproduce compilation errors",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('--project',
                       required=True,
                       help='è¦å¤„ç†çš„é¡¹ç›®åç§° (ä¾‹å¦‚: llvm, opencv)')
    parser.add_argument('--line-number', type=int,
                       help='å¤„ç†æŒ‡å®šè¡Œå·çš„è®°å½• (ä»1å¼€å§‹)')
    parser.add_argument('--first-n', type=int,
                       help='å¤„ç†å‰Næ¡è®°å½•')
    parser.add_argument('--dry-run', action='store_true',
                       help='ä»…æ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„æ“ä½œï¼Œä¸å®é™…è¿è¡Œ')
    parser.add_argument('--rebuild', action='store_true',
                       help='å¼ºåˆ¶é‡æ–°æ„å»ºç¯å¢ƒ (å¯¹åº” reproduce_error.py çš„ --force-rebuild)')
    parser.add_argument('--list', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è®°å½•')
    parser.add_argument('--no-switch', action='store_true',
                       help='ä¸åˆ‡æ¢åˆ°æŒ‡å®šçš„commit (å¯¹åº” reproduce_error.py çš„ --no-switch)')
    parser.add_argument('--repo-path', type=str,
                       help='æŒ‡å®šä»“åº“è·¯å¾„ (å¯¹åº” reproduce_error.py çš„ --repo-path)')
    parser.add_argument('--reuse-log', type=str,
                        help='æŒ‡å®šè¦å¤ç”¨çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä¸é‡æ–°è¿è¡Œå¤ç°è„šæœ¬')
    
    args = parser.parse_args()
    
    # æ ¹æ®é¡¹ç›®åç§°æ„å»ºJSONLæ–‡ä»¶è·¯å¾„ - ä»find_repair_patchç›®å½•è¯»å–
    jsonl_file = get_repair_patch_file(args.project)

    # åŠ è½½è®°å½•
    print(f"åŠ è½½JSONLæ–‡ä»¶: {jsonl_file}")
    records = load_compiler_errors_data(jsonl_file, args.project)
    print(f"åŠ è½½äº† {len(records)} æ¡è®°å½•")
    
    # åŠ è½½é¡¹ç›®é…ç½®
    project_config = load_project_config(args.project)
    
    # å¦‚æœæ˜¯åˆ—è¡¨æ¨¡å¼ï¼Œæ˜¾ç¤ºè®°å½•å¹¶é€€å‡º
    if args.list:
        list_records(records, args.project, project_config)
        return
    
    # è¿‡æ»¤è®°å½•
    filtered_records = records
    
    if args.line_number:
        # å¤„ç†æŒ‡å®šè¡Œå·
        target_record = None
        for record in filtered_records:
            if record.get('_line_number') == args.line_number:
                target_record = record
                break
        
        if not target_record:
            print(f"é”™è¯¯: æœªæ‰¾åˆ°è¡Œå· {args.line_number} çš„è®°å½•")
            sys.exit(1)
        
        filtered_records = [target_record]
    
    elif args.first_n:
        # å¤„ç†å‰Næ¡è®°å½•
        filtered_records = filtered_records[:args.first_n]
    
    elif not args.list:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•è¿‡æ»¤æ¡ä»¶ï¼Œå¤„ç†ç¬¬ä¸€æ¡è®°å½•
        if filtered_records:
            filtered_records = [filtered_records[0]]
            print("æœªæŒ‡å®šè®°å½•ï¼Œå°†å¤„ç†ç¬¬ä¸€æ¡è®°å½•")
        else:
            print("é”™è¯¯: æ²¡æœ‰å¯å¤„ç†çš„è®°å½•")
            sys.exit(1)
    
    print(f"å°†å¤„ç† {len(filtered_records)} æ¡è®°å½•")
    
    # å¤„ç†è®°å½•
    success_count = 0
    for i, record in enumerate(filtered_records, 1):
        line_num = record.get('_line_number', '?')
        failure_commit = record.get('failure_commit', '')
        workflow_name = record.get('workflow_name', '')
        workflow_id = record.get('workflow_id', '')
        job_name = record.get('job_name', '')
        
        # æ ¹æ®é¡¹ç›®é…ç½®é€‰æ‹©å¯ç¼–è¯‘çš„job
        compilable_job_name = select_compilable_job(job_name, project_config)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯ç¼–è¯‘çš„jobï¼Œè·³è¿‡æ­¤è®°å½•
        if compilable_job_name is None:
            print(f"è·³è¿‡è®°å½• {line_num}: æ²¡æœ‰å¯ç¼–è¯‘çš„job")
            continue
        
        project_name = args.project
        
        print(f"\n{'='*60}")
        print(f"å¤„ç†è®°å½• {i}/{len(filtered_records)} (è¡Œå·: {line_num})")
        print(f"é¡¹ç›®: {project_name}")
        print(f"å¤±è´¥commit: {failure_commit}")
        print(f"Workflow: {workflow_name}")
        print(f"ä½œä¸š: {compilable_job_name}")
        print(f"{'='*60}")
        
        # éªŒè¯å¿…è¦å‚æ•°
        if not failure_commit:
            print("é”™è¯¯: ç¼ºå°‘failure_commit")
            continue
        
        if not workflow_name:
            print("é”™è¯¯: ç¼ºå°‘workflow_name")
            continue
        
        # è¿è¡Œå¤ç°
        success = run_reproduction(
            project_name, failure_commit, compilable_job_name, workflow_name, line_num, args.dry_run, args.rebuild, args.no_switch, args.repo_path, args.reuse_log
        )
        
        if success:
            success_count += 1
            print(f"âœ“ è®°å½• {line_num} å¤„ç†æˆåŠŸ")
        else:
            print(f"âœ— è®°å½• {line_num} å¤„ç†å¤±è´¥")
    
    print(f"\næ€»ç»“: {success_count}/{len(filtered_records)} æ¡è®°å½•å¤„ç†æˆåŠŸ")


if __name__ == "__main__":
    main() 

if __name__ == "__main__":
    main() 


if __name__ == "__main__":
    main() 
