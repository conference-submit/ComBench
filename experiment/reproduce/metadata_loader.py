#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Metadata loading module

Load expected compilation error information from JSONL files in find_repair_patch directory
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Optional

class MetadataLoader:
    """Metadata loader"""
    
    def __init__(self):
        # Set find_repair_patch directory path
        script_dir = Path(__file__).parent
        self.find_repair_patch_dir = script_dir.parent.parent / "find_repair_patch"
        self.compilation_error_dir = script_dir.parent.parent / "compilation_error"
        
        if not self.find_repair_patch_dir.exists():
            print(f"âš ï¸ find_repair_patch directory does not exist: {self.find_repair_patch_dir}")
        
        if not self.compilation_error_dir.exists():
            print(f"âš ï¸ compilation_error directory does not exist: {self.compilation_error_dir}")
    
    def get_metadata_file_path(self, project_name: str) -> Optional[Path]:
        """
        Get project metadata file path
        
        Args:
            project_name: Project name
            
        Returns:
            Metadata file path, returns None if not exists
        """
        # First search in find_repair_patch directory
        possible_filenames = [
            f"{project_name}_repair_analysis.jsonl",
            f"{project_name}_repair_analysis.json",
            f"{project_name.lower()}_repair_analysis.jsonl",
            f"{project_name.upper()}_repair_analysis.jsonl",
        ]
        
        for filename in possible_filenames:
            file_path = self.find_repair_patch_dir / filename
            if file_path.exists():
                return file_path
        
        # If not found in find_repair_patch directory, try compilation_error directory
        compilation_error_filenames = [
            f"{project_name}_compiler_errors_extracted.json",
            f"{project_name.lower()}_compiler_errors_extracted.json",
            f"{project_name.upper()}_compiler_errors_extracted.json",
        ]
        
        for filename in compilation_error_filenames:
            file_path = self.compilation_error_dir / filename
            if file_path.exists():
                return file_path
        
        return None
    
    def load_metadata_records(self, file_path: Path) -> List[Dict]:
        """
        Load all records from JSONL or JSON file
        
        Args:
            file_path: File path
            
        Returns:
            Record list
        """
        records = []
        
        try:
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ¥å†³å®šè¯»å–æ–¹å¼
            if file_path.suffix.lower() == '.json':
                # JSONæ ¼å¼æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ä»JSONæ•°æ®ä¸­æå–compiler_errorsæ•°ç»„
                if 'compiler_errors' in data:
                    compiler_errors = data['compiler_errors']
                    for line_num, record in enumerate(compiler_errors, 1):
                        # æ·»åŠ è¡Œå·ä¿¡æ¯
                        record['_line_number'] = line_num
                        # å°†commit_shaæ˜ å°„ä¸ºfailure_commitä»¥ä¿æŒå…¼å®¹æ€§
                        if 'commit_sha' in record:
                            record['failure_commit'] = record['commit_sha']
                        records.append(record)
                    
                    print(f"ğŸ“š ä»JSONæ–‡ä»¶{file_path}åŠ è½½äº† {len(records)} æ¡è®°å½•")
                else:
                    print(f"âŒ JSONæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°compiler_errorså­—æ®µ")
                    
            else:
                # JSONLæ ¼å¼æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        if not line:
                            continue
                        
                        try:
                            record = json.loads(line)
                            record['_line_number'] = line_num
                            records.append(record)
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸ è§£æç¬¬{line_num}è¡ŒJSONæ—¶å‡ºé”™: {e}")
                            continue
                            
                print(f"ğŸ“š ä»JSONLæ–‡ä»¶{file_path}åŠ è½½äº† {len(records)} æ¡è®°å½•")
            
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        return records
    
    def find_matching_record(self, records: List[Dict], failure_commit: str, 
                           job_name: str, workflow_name: str) -> Optional[Dict]:
        """
        æ ¹æ®æ¡ä»¶æŸ¥æ‰¾åŒ¹é…çš„è®°å½•
        
        Args:
            records: è®°å½•åˆ—è¡¨
            failure_commit: å¤±è´¥çš„commit SHA
            job_name: ä½œä¸šåç§°
            workflow_name: workflowåç§°
            
        Returns:
            åŒ¹é…çš„è®°å½•ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        for record in records:
            # æ£€æŸ¥commitåŒ¹é…
            record_commit = record.get('failure_commit', '')
            if record_commit and failure_commit:
                # æ”¯æŒçŸ­commit SHAåŒ¹é…
                if len(failure_commit) >= 7 and len(record_commit) >= 7:
                    if record_commit.startswith(failure_commit[:7]) or failure_commit.startswith(record_commit[:7]):
                        commit_match = True
                    else:
                        commit_match = record_commit == failure_commit
                else:
                    commit_match = record_commit == failure_commit
            else:
                commit_match = False
            
            # æ£€æŸ¥jobåç§°åŒ¹é…ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
            record_job = record.get('job_name', '')
            
            # å¤„ç†job_nameå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
            if isinstance(record_job, list):
                job_match = job_name in record_job
            else:
                job_match = (
                    record_job == job_name or
                    job_name in record_job or
                    record_job in job_name
                )
            
            # æ£€æŸ¥workflowåç§°åŒ¹é…ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰
            record_workflow = record.get('workflow_name', '')
            
            # å¤„ç†workflow_nameå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
            if isinstance(record_workflow, list):
                workflow_match = workflow_name in record_workflow
            else:
                workflow_match = (
                    record_workflow == workflow_name or
                    workflow_name in record_workflow or
                    record_workflow in workflow_name
                )
            
            # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½åŒ¹é…
            if commit_match and job_match and workflow_match:
                print(f"âœ… æ‰¾åˆ°åŒ¹é…è®°å½• (è¡Œå·: {record.get('_line_number', '?')})")
                print(f"   Commit: {record_commit}")
                print(f"   Job: {record_job}")
                print(f"   Workflow: {record_workflow}")
                return record
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ï¼Œå°è¯•åªåŒ¹é…commit
        print(f"âš ï¸ æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„è®°å½•ï¼Œå°è¯•åªåŒ¹é…commit...")
        for record in records:
            record_commit = record.get('failure_commit', '')
            if record_commit and failure_commit:
                if len(failure_commit) >= 7 and len(record_commit) >= 7:
                    if record_commit.startswith(failure_commit[:7]) or failure_commit.startswith(record_commit[:7]):
                        print(f"âš ï¸ æ‰¾åˆ°commitåŒ¹é…è®°å½• (è¡Œå·: {record.get('_line_number', '?')})")
                        print(f"   Commit: {record_commit}")
                        print(f"   Job: {record.get('job_name', '')}")
                        print(f"   Workflow: {record.get('workflow_name', '')}")
                        return record
        
        return None
    
    def extract_error_lines(self, record: Dict) -> List[Dict]:
        """
        ä»è®°å½•ä¸­æå–é”™è¯¯è¡Œä¿¡æ¯
        
        Args:
            record: å…ƒæ•°æ®è®°å½•
            
        Returns:
            é”™è¯¯è¡Œä¿¡æ¯åˆ—è¡¨
        """
        error_lines = []
        
        # å°è¯•ä¸åŒçš„å­—æ®µåæ¥è·å–é”™è¯¯ä¿¡æ¯
        possible_fields = [
            'error_lines',
            'error_details', 
            'compilation_errors',
            'errors',
            'failure_details'
        ]
        
        for field in possible_fields:
            if field in record:
                field_value = record[field]
                
                if isinstance(field_value, list):
                    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                    for item in field_value:
                        if isinstance(item, str):
                            error_lines.append({'error_text': item})
                        elif isinstance(item, dict):
                            error_lines.append(item)
                elif isinstance(field_value, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒåŒ…è£…æˆå­—å…¸
                    error_lines.append({'error_text': field_value})
                elif isinstance(field_value, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå¯èƒ½åŒ…å«åµŒå¥—çš„é”™è¯¯ä¿¡æ¯
                    if 'error_lines' in field_value:
                        nested_errors = field_value['error_lines']
                        if isinstance(nested_errors, list):
                            for item in nested_errors:
                                if isinstance(item, str):
                                    error_lines.append({'error_text': item})
                                elif isinstance(item, dict):
                                    error_lines.append(item)
                
                # å¦‚æœæ‰¾åˆ°äº†é”™è¯¯ä¿¡æ¯ï¼Œå°±ä¸å†æ£€æŸ¥å…¶ä»–å­—æ®µ
                if error_lines:
                    break
        
        return error_lines
    
    def load_expected_errors(self, project_name: str, failure_commit: str, 
                           job_name: str, workflow_name: str) -> List[Dict]:
        """
        åŠ è½½é¢„æœŸçš„é”™è¯¯ä¿¡æ¯
        
        Args:
            project_name: Project name
            failure_commit: å¤±è´¥çš„commit SHA
            job_name: ä½œä¸šåç§°
            workflow_name: workflowåç§°
            
        Returns:
            é¢„æœŸé”™è¯¯ä¿¡æ¯åˆ—è¡¨
        """
        print(f"ğŸ“– åŠ è½½é¡¹ç›® {project_name} çš„é¢„æœŸé”™è¯¯ä¿¡æ¯...")
        
        # è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        metadata_file = self.get_metadata_file_path(project_name)
        if not metadata_file:
            print(f"âŒ æœªæ‰¾åˆ°é¡¹ç›® {project_name} çš„å…ƒæ•°æ®æ–‡ä»¶")
            return []
        
        print(f"ğŸ“ ä½¿ç”¨å…ƒæ•°æ®æ–‡ä»¶: {metadata_file}")
        
        # åŠ è½½æ‰€æœ‰è®°å½•
        records = self.load_metadata_records(metadata_file)
        if not records:
            print("âŒ æœªåŠ è½½åˆ°ä»»ä½•è®°å½•")
            return []
        
        # æŸ¥æ‰¾åŒ¹é…çš„è®°å½•
        matching_record = self.find_matching_record(
            records, failure_commit, job_name, workflow_name
        )
        
        if not matching_record:
            print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è®°å½•")
            return []
        
        # æå–é”™è¯¯è¡Œä¿¡æ¯
        error_lines = self.extract_error_lines(matching_record)
        
        if error_lines:
            print(f"âœ… æå–åˆ° {len(error_lines)} æ¡é¢„æœŸé”™è¯¯")
        else:
            print("âš ï¸ åŒ¹é…è®°å½•ä¸­æœªæ‰¾åˆ°é”™è¯¯è¡Œä¿¡æ¯")
        
        return error_lines
    
    def list_available_projects(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é¡¹ç›®
        
        Returns:
            é¡¹ç›®åç§°åˆ—è¡¨
        """
        projects = []
        
        if not self.find_repair_patch_dir.exists():
            return projects
        
        # æŸ¥æ‰¾æ‰€æœ‰*_repair_analysis.jsonlæ–‡ä»¶
        for file_path in self.find_repair_patch_dir.glob("*_repair_analysis.jsonl"):
            project_name = file_path.stem.replace("_repair_analysis", "")
            projects.append(project_name)
        
        return sorted(projects)
    
    def get_project_statistics(self, project_name: str) -> Dict[str, any]:
        """
        è·å–é¡¹ç›®çš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            project_name: Project name
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        metadata_file = self.get_metadata_file_path(project_name)
        if not metadata_file:
            return {'error': 'æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶'}
        
        records = self.load_metadata_records(metadata_file)
        
        if not records:
            return {'error': 'æœªåŠ è½½åˆ°è®°å½•'}
        
        # æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        unique_commits = set()
        unique_jobs = set()
        unique_workflows = set()
        total_errors = 0
        
        for record in records:
            if 'failure_commit' in record:
                unique_commits.add(record['failure_commit'])
            if 'job_name' in record:
                unique_jobs.add(record['job_name'])
            if 'workflow_name' in record:
                unique_workflows.add(record['workflow_name'])
            
            # ç»Ÿè®¡é”™è¯¯æ•°é‡
            error_lines = self.extract_error_lines(record)
            total_errors += len(error_lines)
        
        return {
            'total_records': len(records),
            'unique_commits': len(unique_commits),
            'unique_jobs': len(unique_jobs),
            'unique_workflows': len(unique_workflows),
            'total_errors': total_errors,
            'metadata_file': str(metadata_file)
        } 