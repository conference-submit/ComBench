#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¼–è¯‘é”™è¯¯å¤ç°å’ŒéªŒè¯è„šæœ¬

è¯¥è„šæœ¬è¢«batch_reproduce_project.pyè°ƒç”¨ï¼Œç”¨äºï¼š
1. è°ƒç”¨reproduce_error.pyè¿è¡ŒCI workflow
2. ä»è¾“å‡ºæ—¥å¿—ä¸­æå–ç¼–è¯‘é”™è¯¯
3. ä¸find_repair_patchç›®å½•ä¸‹çš„å…ƒæ•°æ®å¯¹æ¯”
4. åˆ¤æ–­é”™è¯¯ä¿¡æ¯æ˜¯å¦ä¸€è‡´ï¼Œç¡®å®šreproduceæ˜¯å¦æˆåŠŸ

ä½¿ç”¨æ–¹æ³•:
    python reproduce_compiler_errors.py <project_name> <failure_commit> <job_name> <workflow_name> [--output OUTPUT]
"""

import argparse
import json
import os
import subprocess
import sys
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import re

def run_reproduce_script(project_name: str, failure_commit: str, job_name: str, workflow_name: str, 
                        workflow_id: str = None, line_number: Optional[int] = None, timeout: int = 43200) -> Tuple[bool, str, str]:
    """
    è¿è¡Œreproduce_error.pyè„šæœ¬
    
    Returns:
        Tuple[bool, str, str]: (æ˜¯å¦æˆåŠŸ, æ ‡å‡†è¾“å‡º, æ ‡å‡†é”™è¯¯)
    """
    print(f"\n{'='*60}")
    print("å¼€å§‹ç¼–è¯‘é”™è¯¯å¤ç°å’ŒéªŒè¯")
    print(f"é¡¹ç›®: {project_name}")
    print(f"Commit: {failure_commit}")
    print(f"Job: {job_name}")
    print(f"Workflow: {workflow_name}")
    if workflow_id:
        print(f"Workflow ID: {workflow_id}")
    print(f"{'='*60}\n")
    
    print("ğŸš€ å¼€å§‹è¿è¡Œå¤ç°è„šæœ¬...")
    
    script_dir = Path(__file__).parent.parent
    reproduce_script = script_dir / "reproduce_error.py"
    
    cmd = [
        "python3", str(reproduce_script),
        project_name, failure_commit, job_name, workflow_name
    ]
    
    # æ·»åŠ workflow_idå‚æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
    if workflow_id:
        cmd.append(workflow_id)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›workflow_idï¼Œä½¿ç”¨é»˜è®¤å€¼
        cmd.append("0")
    
    if line_number:
        cmd.extend(['--line-number', str(line_number)])
    
    print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        # è¿è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=str(script_dir)
        )
        
        success = result.returncode == 0
        stdout = result.stdout or ""
        stderr = result.stderr or ""
        
        if success:
            print("âœ… å¤ç°è„šæœ¬è¿è¡ŒæˆåŠŸ")
        else:
            print(f"âŒ å¤ç°è„šæœ¬è¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
            
        return success, stdout, stderr
        
    except subprocess.TimeoutExpired:
        print(f"â° å¤ç°è„šæœ¬è¿è¡Œè¶…æ—¶ ({timeout}ç§’)")
        return False, "", "è¶…æ—¶"
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤ç°è„šæœ¬æ—¶å‡ºé”™: {e}")
        return False, "", str(e)

def extract_log_file_path(stdout: str) -> Optional[str]:
    """ä»è¾“å‡ºä¸­æå–æ—¥å¿—æ–‡ä»¶è·¯å¾„"""
    # æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶è·¯å¾„
    log_pattern = r"ğŸ“ æ—¥å¿—æ–‡ä»¶: (.*\.log)"
    match = re.search(log_pattern, stdout)
    if match:
        log_file = match.group(1).strip()
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        if not os.path.isabs(log_file):
            script_dir = Path(__file__).parent.parent
            log_file = str(script_dir / log_file)
        print(f"âœ… æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶: {log_file}")
        return log_file
    
    print("âŒ æœªåœ¨è¾“å‡ºä¸­æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶è·¯å¾„")
    print(f"è¾“å‡ºå†…å®¹: {repr(stdout[:1000])}")  # è°ƒè¯•ä¿¡æ¯
    return None

def extract_compiler_errors(log_content: str) -> List[str]:
    """ä»æ—¥å¿—ä¸­æå–ç¼–è¯‘é”™è¯¯"""
    print("ğŸ” ä»æ—¥å¿—ä¸­æå–ç¼–è¯‘é”™è¯¯...")
    from error_extractor import ErrorExtractor
    extractor = ErrorExtractor()
    errors = extractor.extract_errors(log_content)
    
    print(f"âœ… æå–åˆ° {len(errors)} ä¸ªç¼–è¯‘é”™è¯¯")
    return errors

def load_expected_errors(project_name: str, failure_commit: str, job_name: str, workflow_name: str) -> List[Dict]:
    """åŠ è½½é¢„æœŸçš„é”™è¯¯ä¿¡æ¯"""
    print("ğŸ“š åŠ è½½é¢„æœŸçš„é”™è¯¯ä¿¡æ¯...")
    
    from metadata_loader import MetadataLoader
    
    loader = MetadataLoader()
    
    # è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
    metadata_file = loader.get_metadata_file_path(project_name)
    if not metadata_file:
        print(f"âŒ æœªæ‰¾åˆ°é¡¹ç›® {project_name} çš„å…ƒæ•°æ®æ–‡ä»¶")
        return []
    
    # åŠ è½½æ‰€æœ‰è®°å½•
    records = loader.load_metadata_records(metadata_file)
    if not records:
        print("âŒ æœªåŠ è½½åˆ°ä»»ä½•è®°å½•")
        return []
    
    # æŸ¥æ‰¾åŒ¹é…çš„è®°å½•
    matching_record = loader.find_matching_record(records, failure_commit, job_name, workflow_name)
    if not matching_record:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è®°å½•")
        return []
    
    error_lines = matching_record.get('error_lines', [])
    print(f"âœ… æ‰¾åˆ°åŒ¹é…çš„è®°å½•ï¼ŒåŒ…å« {len(error_lines)} ä¸ªé¢„æœŸé”™è¯¯")
    return [{'error_lines': [err]} for err in error_lines]

def compare_errors(actual_errors: List[str], expected_errors: List[Dict]) -> Dict:
    """æ¯”è¾ƒå®é™…é”™è¯¯å’Œé¢„æœŸé”™è¯¯"""
    print("\nğŸ” æ¯”è¾ƒå®é™…é”™è¯¯å’Œé¢„æœŸé”™è¯¯...")
    
    from error_matcher import ErrorMatcher
    
    matcher = ErrorMatcher()
    
    # ä½¿ç”¨ErrorMatcherè¿›è¡ŒåŒ¹é…
    match_result = matcher.match_errors(actual_errors, expected_errors)
    
    # åˆ¤æ–­æ˜¯å¦æˆåŠŸåŒ¹é…
    match_count = match_result.get('match_count', 0)
    similarity_score = match_result.get('similarity_score', 0.0)
    success = (
        match_count >= len(expected_errors) * 0.8 and  # è‡³å°‘åŒ¹é…80%çš„é¢„æœŸé”™è¯¯
        similarity_score >= 0.6                        # æ€»ä½“ç›¸ä¼¼åº¦è‡³å°‘0.6
    )
    
    # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
    result = {
        'success': success,
        'reason': 'æ‰€æœ‰é”™è¯¯éƒ½æˆåŠŸåŒ¹é…' if success else match_result.get('reason', 'æœªçŸ¥é”™è¯¯'),
        'actual_count': match_result.get('actual_count', 0),
        'expected_count': match_result.get('expected_count', 0),
        'matched_errors': match_result.get('matched_errors', []),
        'similarity_score': similarity_score,
        'match_count': match_count  # æ·»åŠ åŒ¹é…æ•°é‡å­—æ®µ
    }
    
    print(f"ğŸ“Š åŒ¹é…ç»“æœ:")
    print(f"   å®é™…é”™è¯¯æ•°: {result['actual_count']}")
    print(f"   é¢„æœŸé”™è¯¯æ•°: {result['expected_count']}")
    print(f"   åŒ¹é…é”™è¯¯æ•°: {match_count}")
    print(f"   æ€»ä½“ç›¸ä¼¼åº¦: {similarity_score:.3f}")
    print(f"   åŒ¹é…ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
    print(f"   åŒ¹é…åŸå› : {match_result.get('reason', 'æœªçŸ¥é”™è¯¯')}")
    
    # æ˜¾ç¤ºè¯¦ç»†çš„åŒ¹é…ä¿¡æ¯
    matched_errors = match_result.get('matched_errors', [])
    if matched_errors:
        print("ğŸ” åŒ¹é…è¯¦æƒ…:")
        for i, match in enumerate(matched_errors[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ªåŒ¹é…
            similarity = match.get('similarity', 0.0)
            actual_error = match.get('actual_error', 'æœªçŸ¥é”™è¯¯')
            expected_error = match.get('expected_error', 'æœªçŸ¥é”™è¯¯')
            print(f"   åŒ¹é…{i} (ç›¸ä¼¼åº¦: {similarity:.3f}):")
            print(f"     å®é™…: {actual_error[:80]}...")
            expected_text = str(expected_error)
            print(f"     é¢„æœŸ: {expected_text[:80]}...")
    
    return result

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument('project_name',
                       help='é¡¹ç›®åç§° (å¦‚: llvm)')
    parser.add_argument('failure_commit',
                       help='å¤±è´¥çš„commit SHA')
    parser.add_argument('job_name',
                       help='ä½œä¸šåç§°')
    parser.add_argument('workflow_name',
                       help='workflowåç§°')
    parser.add_argument('workflow_id',
                       help='workflow ID (å¯é€‰ï¼Œé»˜è®¤ä¸º0)')
    parser.add_argument('--output',
                       help='è¾“å‡ºç»“æœåˆ°JSONæ–‡ä»¶')
    parser.add_argument('--timeout', type=int, default=43200,
                       help='è¿è¡Œè¶…æ—¶æ—¶é—´(ç§’)')
    parser.add_argument('--line-number', type=int,
                       help='JSONLæ–‡ä»¶ä¸­çš„è¡Œå·ï¼Œç”¨äºæ—¥å¿—æ–‡ä»¶å‘½å')
    parser.add_argument('--reuse-log', action='store_true',
                       help='å¦‚æœæ—¥å¿—æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥å¤ç”¨ï¼Œä¸é‡æ–°è¿è¡Œå¤ç°è„šæœ¬')
    
    args = parser.parse_args()
    
    start_time = time.time()

    # æ„é€ æ—¥å¿—æ–‡ä»¶åï¼ˆå’ŒåŸæœ‰è„šæœ¬ä¸€è‡´ï¼‰
    line_num = args.line_number if args.line_number is not None else 0
    log_file = f"logs/act_{args.project_name}_line{line_num}.log"
    print(f"   ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    log_file_path = log_file
    if not os.path.isabs(log_file_path):
        script_dir = Path(__file__).parent.parent
        log_file_path = str(script_dir / log_file_path)

    # å¦‚æœæ—¥å¿—æ–‡ä»¶å·²å­˜åœ¨ä¸”å¯ç”¨äº†å¤ç”¨é€‰é¡¹ï¼Œç›´æ¥åŠ è½½
    if args.reuse_log and os.path.exists(log_file_path):
        print(f"âœ… æ—¥å¿—æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¯ç”¨å¤ç”¨æ¨¡å¼ï¼Œç›´æ¥åŠ è½½: {log_file_path}")
        try:
            with open(log_file_path, 'r', encoding='utf-8') as f:
                log_content = f.read()
            actual_errors = extract_compiler_errors(log_content)
            expected_errors = load_expected_errors(
                args.project_name,
                args.failure_commit,
                args.job_name,
                args.workflow_name
            )
            comparison = compare_errors(actual_errors, expected_errors)
            result = {
                'success': comparison.get('success', False),
                'stage': 'verification',
                'reason': comparison.get('reason', 'æœªçŸ¥é”™è¯¯'),
                'log_file': log_file_path,
                'actual_errors': actual_errors,
                'expected_errors': expected_errors,
                'comparison': comparison,
                'elapsed_time': time.time() - start_time
            }
        except Exception as e:
            result = {
                'success': False,
                'stage': 'error_processing',
                'reason': f'å¤„ç†é”™è¯¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}',
                'log_file': log_file_path,
                'elapsed_time': time.time() - start_time
            }
    else:
        if os.path.exists(log_file_path):
            print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½†æœªå¯ç”¨å¤ç”¨æ¨¡å¼ï¼Œå°†é‡æ–°è¿è¡Œå¤ç°è„šæœ¬: {log_file_path}")
        else:
            print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è¿è¡Œå¤ç°è„šæœ¬ç”Ÿæˆ: {log_file_path}")
        # æ­¥éª¤1: è¿è¡Œå¤ç°è„šæœ¬
        success, stdout, stderr = run_reproduce_script(
            args.project_name,
            args.failure_commit,
            args.job_name,
            args.workflow_name,
            args.workflow_id,
            args.line_number,
            args.timeout
        )
        if not success:
            result = {
                'success': False,
                'stage': 'reproduce_script',
                'reason': 'å¤ç°è„šæœ¬è¿è¡Œå¤±è´¥',
                'stdout': stdout,
                'stderr': stderr,
                'elapsed_time': time.time() - start_time
            }
        else:
            # æ­¥éª¤2: æå–æ—¥å¿—æ–‡ä»¶è·¯å¾„
            log_file = extract_log_file_path(stdout)
            if not log_file:
                result = {
                    'success': False,
                    'stage': 'log_extraction',
                    'reason': 'æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶',
                    'stdout': stdout,
                    'stderr': stderr,
                    'elapsed_time': time.time() - start_time
                }
            else:
                try:
                    # æ­¥éª¤3: è¯»å–æ—¥å¿—æ–‡ä»¶
                    with open(log_file, 'r', encoding='utf-8') as f:
                        log_content = f.read()
                    # æ­¥éª¤4: æå–ç¼–è¯‘é”™è¯¯
                    actual_errors = extract_compiler_errors(log_content)
                    # æ­¥éª¤5: åŠ è½½é¢„æœŸé”™è¯¯
                    expected_errors = load_expected_errors(
                        args.project_name,
                        args.failure_commit,
                        args.job_name,
                        args.workflow_name
                    )
                    # æ­¥éª¤6: æ¯”è¾ƒé”™è¯¯
                    comparison = compare_errors(actual_errors, expected_errors)
                    result = {
                        'success': comparison.get('success', False),
                        'stage': 'verification',
                        'reason': comparison.get('reason', 'æœªçŸ¥é”™è¯¯'),
                        'log_file': log_file,
                        'actual_errors': actual_errors,
                        'expected_errors': expected_errors,
                        'comparison': comparison,
                        'elapsed_time': time.time() - start_time
                    }
                except Exception as e:
                    result = {
                        'success': False,
                        'stage': 'error_processing',
                        'reason': f'å¤„ç†é”™è¯¯æ—¶å‘ç”Ÿå¼‚å¸¸: {e}',
                        'log_file': log_file,
                        'elapsed_time': time.time() - start_time
                    }
    # è¾“å‡ºç»“æœ
    if args.output:
        try:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        except Exception as e:
            print(f"\nâŒ ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
    # è®¾ç½®é€€å‡ºç 
    sys.exit(0 if result['success'] else 1)

if __name__ == "__main__":
    main() 